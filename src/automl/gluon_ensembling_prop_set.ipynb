{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a script to to load the property dataset and run **AutoGluon** on it. First basic model run, then different configurations are tried. Then look at possible **third level ensembling** of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isak\\miniconda3\\envs\\automl-tabular-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for loading one of the 10 folds of the property dataset and concatinating the X and y values for train and test respectively. \n",
    "import pandas as pd\n",
    "\n",
    "def load_fold(fold_number, random_seed=42, sample_size=None):\n",
    "    df_X_train = pd.read_parquet(f'../../data/361092/{fold_number}1/X_train.parquet')\n",
    "    df_y_train = pd.read_parquet(f'../../data/361092/{fold_number}/y_train.parquet')\n",
    "    df_X_test = pd.read_parquet(f'../../data/361092/{fold_number}/X_test.parquet')\n",
    "    df_y_test = pd.read_parquet(f'../../data/361092/{fold_number}/y_test.parquet')\n",
    "\n",
    "    # concatinating the X and y values for train and test respectively\n",
    "    df_train = pd.concat([df_X_train, df_y_train], axis=1)\n",
    "    df_test = pd.concat([df_X_test, df_y_test], axis=1)\n",
    "\n",
    "    # Convert to AutoGluon's TabularDataset\n",
    "    if sample_size:\n",
    "        train_dataset = TabularDataset(df_train).sample(n=sample_size, random_state=random_seed)\n",
    "        test_dataset = TabularDataset(df_test).sample(n=sample_size, random_state=random_seed)\n",
    "    else:\n",
    "        train_dataset = TabularDataset(df_train)\n",
    "        test_dataset = TabularDataset(df_test)\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Also instantiate the target column\n",
    "label_property = 'oz252'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionary containing the hyperparameters for the different AutoGluon models\n",
    "# First we make one dict, but later on trying different variaties for the lvl 1 and 2 models\n",
    "\n",
    "hyperparameters = {\n",
    "    'GBM': [\n",
    "        {'learning_rate': 0.1, 'num_leaves': 31, 'feature_fraction': 0.9},\n",
    "        {'learning_rate': 0.05, 'num_leaves': 45, 'feature_fraction': 0.8},\n",
    "    ],\n",
    "    'CAT': {\n",
    "        'iterations': 1000,\n",
    "        'depth': 7,\n",
    "        'learning_rate': 0.1,\n",
    "        'l2_leaf_reg': 3,\n",
    "    },\n",
    "    'XGB': {\n",
    "        'n_estimators': 1000,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'subsample': 0.8,\n",
    "    },\n",
    "    'NN_TORCH': {\n",
    "        'num_epochs': 10,\n",
    "        'learning_rate': 1e-3,\n",
    "        'layers': [100, 100],\n",
    "    },\n",
    "    'RF': {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 15,\n",
    "        'min_samples_split': 2,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to fit the model, first with base parameter config options, but later adding more advanced options\n",
    "\n",
    "def fit_gluon(train_dataset, problem_type='regression', label_property=label_property, hyperparameters=None, eval_metric='r2', presets='medium_quality', time_limits=100):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl-tabular-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
