{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht4hg37xc-51"
      },
      "source": [
        "### This is a script to to load the property dataset and run **AutoGluon** on it. First basic model run, then different configurations are tried. Then look at possible **third level ensembling** of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "vWxQZEEH2uHi",
        "outputId": "97867842-4242-4171-bbba-ab92979f522d"
      },
      "outputs": [],
      "source": [
        "### installments\n",
        "\n",
        "!pip install autogluon\n",
        "!sudo apt-get install graphviz graphviz-dev\n",
        "!pip install pygraphviz\n",
        "!pip install tabpfn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0Vb0n1Byc-53"
      },
      "outputs": [],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j1XO9F5dc-55"
      },
      "outputs": [],
      "source": [
        "random_seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzT9Zhk1ebZZ",
        "outputId": "b7250b48-f8c3-4fdc-f091-b4e53cca033c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/My Drive/361092'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0hLSX-NEc-55"
      },
      "outputs": [],
      "source": [
        "## Function for loading one of the 10 folds of the property dataset and concatinating the X and y values for train and test respectively.\n",
        "import pandas as pd\n",
        "\n",
        "base_path = '../../data/361092' # Use this when running locally\n",
        "\n",
        "def load_fold(fold_number, random_seed=42, sample_size=None):\n",
        "    df_X_train = pd.read_parquet(f'{base_path}/{fold_number}/X_train.parquet')\n",
        "    df_y_train = pd.read_parquet(f'{base_path}/{fold_number}/y_train.parquet')\n",
        "    df_X_test = pd.read_parquet(f'{base_path}/{fold_number}/X_test.parquet')\n",
        "    df_y_test = pd.read_parquet(f'{base_path}/{fold_number}/y_test.parquet')\n",
        "\n",
        "    # concatinating the X and y values for train and test respectively\n",
        "    df_train = pd.concat([df_X_train, df_y_train], axis=1)\n",
        "    df_test = pd.concat([df_X_test, df_y_test], axis=1)\n",
        "\n",
        "    # Convert to AutoGluon's TabularDataset\n",
        "    if sample_size:\n",
        "        train_dataset = TabularDataset(df_train).sample(n=sample_size, random_state=random_seed)\n",
        "        test_dataset = TabularDataset(df_test).sample(n=sample_size, random_state=random_seed)\n",
        "    else:\n",
        "        train_dataset = TabularDataset(df_train)\n",
        "        test_dataset = TabularDataset(df_test)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "# Also instantiate the target column\n",
        "label_property = 'oz252'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fOvxTvSNc-56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Isak\\Miniconda3\\envs\\automl-tabular-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "## Function to fit the model, with most of the hyperparameters present and set to default/None. (Add more hyperparameters if desirable)\n",
        "\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "def fit_gluon(train_dataset, problem_type='regression', hyperparameters=None, eval_metric='r2', presets='medium_quality', time_limit=100, fit_weighted_ensemble=None, num_cpus = None, num_gpus=None, auto_stack=None, num_bag_folds=None, num_bag_sets=None, num_stack_levels=None, num_trials=None, verbosity=None, ag_args_fit=None, feature_prune=None, excluded_model_types=None, keep_only_best=None):\n",
        "    predictor = TabularPredictor(label=label_property, problem_type=problem_type, eval_metric=eval_metric)\n",
        "\n",
        "    fit_args = {\n",
        "        'train_data': train_dataset,\n",
        "        'presets': presets,\n",
        "        'time_limit': time_limit,\n",
        "    }\n",
        "\n",
        "    if hyperparameters is not None:\n",
        "        fit_args['hyperparameters'] = hyperparameters\n",
        "    if auto_stack is not None:\n",
        "        fit_args['auto_stack'] = auto_stack\n",
        "    if num_bag_folds is not None:\n",
        "        fit_args['num_bag_folds'] = num_bag_folds\n",
        "    if num_bag_sets is not None:\n",
        "        fit_args['num_bag_sets'] = num_bag_sets\n",
        "    if num_stack_levels is not None:\n",
        "        fit_args['num_stack_levels'] = num_stack_levels\n",
        "    if num_trials is not None:\n",
        "        fit_args['num_trials'] = num_trials\n",
        "    if verbosity is not None:\n",
        "        fit_args['verbosity'] = verbosity\n",
        "    if ag_args_fit is not None:\n",
        "        fit_args['ag_args_fit'] = ag_args_fit\n",
        "    if feature_prune is not None:\n",
        "        fit_args['feature_prune'] = feature_prune\n",
        "    if excluded_model_types is not None:\n",
        "        fit_args['excluded_model_types'] = excluded_model_types\n",
        "    if fit_weighted_ensemble is not None:\n",
        "        fit_args['fit_weighted_ensemble'] = fit_weighted_ensemble\n",
        "    if num_cpus is not None:\n",
        "        fit_args['num_cpus'] = num_cpus\n",
        "    if num_gpus is not None:\n",
        "        fit_args['num_gpus'] = num_gpus\n",
        "    if keep_only_best is not None:\n",
        "        fit_args['keep_only_best'] = keep_only_best\n",
        "\n",
        "    predictor.fit(**fit_args)\n",
        "    return predictor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sQIUKVDbc-56"
      },
      "outputs": [],
      "source": [
        "## Function to evaluate a fitted model and training set.\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def evaluate_gluon(model, test_dataset):\n",
        "\n",
        "    leaderboard = model.leaderboard(test_dataset, only_pareto_frontier=True)\n",
        "\n",
        "    y_test = test_dataset[label_property]\n",
        "    x_test = test_dataset.drop(columns=[label_property])\n",
        "    y_pred = model.predict(x_test)\n",
        "    test_score = model.evaluate_predictions(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "    #path_to_png = model.plot_ensemble_model()\n",
        "    #L2_diagram = display(Image(filename=path_to_png))\n",
        "\n",
        "\n",
        "    return test_score, leaderboard #, L2_diagram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1QLLrP5uc-57",
        "outputId": "d3dc84d9-14bd-4594-f586-a814edf8adc6"
      },
      "outputs": [],
      "source": [
        "## First training the model speratly on all 10 folds to see that it is consistent\n",
        "\n",
        "for fold_number in range(1, 11): # jsut the first to start with\n",
        "    train_dataset, test_dataset = load_fold(fold_number, random_seed=random_seed)\n",
        "    model = fit_gluon(train_dataset, time_limit=100, verbosity=1, keep_only_best=True)\n",
        "    test_score, leaderboard = evaluate_gluon(model, test_dataset)\n",
        "    print(f'Fold {fold_number}\\n\\n: {test_score} \\n\\n')\n",
        "    print(leaderboard.head())\n",
        "    #print(model.fit_summary())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## First training the model speratly on all 10 folds to see that it is consistent\n",
        "\n",
        "for fold_number in range(1, 11): # jsut the first to start with\n",
        "    train_dataset, test_dataset = load_fold(fold_number, random_seed=random_seed)\n",
        "    model = fit_gluon(train_dataset, time_limit=300, presets=['medium_quality', 'optimize_for_deployment'], verbosity=1)\n",
        "    test_score, leaderboard = evaluate_gluon(model, test_dataset)\n",
        "    print(f'Fold {fold_number}\\n\\n: {test_score} \\n\\n')\n",
        "    print(leaderboard.head())\n",
        "    #print(model.fit_summary())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "93vNiSqRc-58",
        "outputId": "abf7c73d-1365-43a8-d1fb-b4da2a70d5bd"
      },
      "outputs": [],
      "source": [
        "## Making sets of all 10 folds\n",
        "\n",
        "full_train = None\n",
        "full_test = None\n",
        "\n",
        "for fold_number in range(1, 11):\n",
        "    train_dataset, test_dataset = load_fold(fold_number, random_seed=random_seed)\n",
        "    if full_train is None:\n",
        "        full_train = train_dataset\n",
        "        full_test = test_dataset\n",
        "    else:\n",
        "        # Use pd.concat to combine TabularDatasets\n",
        "        full_train = pd.concat([full_train, train_dataset])\n",
        "        full_test = pd.concat([full_test, test_dataset])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "\n",
        "def load_predictors(start_time, end_time, folder='AutogluonModels'):\n",
        "    \"\"\"\n",
        "    Load AutoGluon predictors created within a specified time interval.\n",
        "    \n",
        "    :param start_time: Start of the time interval (str in format 'YYYYMMDD_HHMMSS')\n",
        "    :param end_time: End of the time interval (str in format 'YYYYMMDD_HHMMSS')\n",
        "    :param folder: Folder containing the AutoGluon models\n",
        "    :return: List of loaded predictors\n",
        "    \"\"\"\n",
        "    start_datetime = datetime.strptime(start_time, '%Y%m%d_%H%M%S')\n",
        "    end_datetime = datetime.strptime(end_time, '%Y%m%d_%H%M%S')\n",
        "    \n",
        "    predictors = []\n",
        "    \n",
        "    for item in os.listdir(folder):\n",
        "        if item.startswith('ag-'):\n",
        "            model_time_str = item.split('-')[1]\n",
        "            model_time = datetime.strptime(model_time_str, '%Y%m%d_%H%M%S')\n",
        "            \n",
        "            if start_datetime <= model_time <= end_datetime:\n",
        "                predictor_path = os.path.join(folder, item)\n",
        "                predictor = TabularPredictor.load(predictor_path)\n",
        "                predictors.append(predictor)\n",
        "    \n",
        "    return predictors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kroZsfJbc-59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 score: 0.47235185168196536\n"
          ]
        }
      ],
      "source": [
        "## Creating ensemble of the trained AutoGluon models on each fold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "start_time = '20240704_124200'\n",
        "end_time = '20240704_125900'\n",
        "\n",
        "loaded_predictors = load_predictors(start_time, end_time)\n",
        "\n",
        "y_test = full_test[label_property]\n",
        "full_test_X = full_test.drop(columns=[label_property])\n",
        "\n",
        "\n",
        "# Simple averaging ensemble\n",
        "ten_fold_ensemble = 0\n",
        "\n",
        "for i in loaded_predictors:\n",
        "    ten_fold_ensemble += i.predict(full_test_X)\n",
        "\n",
        "ten_fold_ensemble = ten_fold_ensemble / 10\n",
        "\n",
        "\n",
        "# Calculate R2 score\n",
        "r2 = r2_score(y_test, ten_fold_ensemble)\n",
        "\n",
        "print(f'R2 score: {r2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "LJ6ZM33xsU1u",
        "outputId": "aa6dafb0-27c2-4238-d208-3d1b784a1e88"
      },
      "outputs": [],
      "source": [
        "## Display the feature importance on the whole dataset trained for a longer\n",
        "## period so we interpret the dataset more correctly\n",
        "\n",
        "model.feature_importance(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f6AT7fM8Q7E",
        "outputId": "20123959-4591-43b0-a183-3ea511364623"
      },
      "outputs": [],
      "source": [
        "## Training the model on all 10 folds\n",
        "\n",
        "model = fit_gluon(full_train, time_limit=100)\n",
        "test_score, leaderboard = evaluate_gluon(model, full_test)\n",
        "print(f'Full Train: {test_score}')\n",
        "display(Image(filename=model.plot_ensemble_model()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "XntN0zoN-4kC",
        "outputId": "d7a5b102-029b-4c63-a4ea-f0619360fa96"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'full_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6e5efe152274>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcolumns_to_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'oz173'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz181'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz31'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz178'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz83'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz87'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz234'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz96'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz135'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz206'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz40'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz73'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz42'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz112'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz113'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz71'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz222'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz108'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oz46'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfull_train_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_to_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfull_test_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_to_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'full_train' is not defined"
          ]
        }
      ],
      "source": [
        "## Training the model again without the least important columns\n",
        "\n",
        "columns_to_drop = ['oz173', 'oz1', 'oz4', 'oz181', 'oz11', 'oz31', 'oz178', 'oz83', 'oz87', 'oz234', 'oz96', 'oz135', 'oz206', 'oz40', 'oz73', 'oz42', 'oz112', 'oz113', 'oz71', 'oz222', 'oz108', 'oz46' ]\n",
        "\n",
        "full_train_drop = full_train.drop(columns=columns_to_drop)\n",
        "full_test_drop = full_test.drop(columns=columns_to_drop)\n",
        "\n",
        "model = fit_gluon(full_train_drop, time_limit=100)\n",
        "test_score, leaderboard = evaluate_gluon(model, full_test_drop)\n",
        "print(f'Full Train: {test_score}')\n",
        "display(Image(filename=model.plot_ensemble_model()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "S9V5pNpp-MiG"
      },
      "outputs": [],
      "source": [
        "## Testing to see if TabPFN works well\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tabpfn import TabPFNClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqrx-Gv5c-58"
      },
      "outputs": [],
      "source": [
        "# Taken from Supriya's code, adjust to local variables\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "\n",
        "\n",
        "# Get the leaderboard\n",
        "leaderboard = predictor.leaderboard(extra_info=['r2'])\n",
        "\n",
        "\n",
        "# # Convert the leaderboard to a DataFrame\n",
        "df = leaderboard.copy()\n",
        "\n",
        "# Set the style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot for validation score (r2)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='model', y='score_val', data=df)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title('Validation Score (R2) by Model')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Validation Score (R2)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
